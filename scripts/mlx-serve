#!/bin/bash
set -euo pipefail

# Available models (shortcuts)
# qwen      = Qwen3-Coder-30B 8-bit (32GB)
# qwen-next = Qwen3-Coder-Next 4-bit (45GB, 80B MoE w/ 3B active)
# glm       = GLM-4.7-Flash 4-bit (17GB) [DEFAULT]
# nemotron  = Nemotron-3-Nano 5-bit (22GB, 1M context)

# Options:
# MLX_MODEL=<shortcut>  Select model (default: glm)
# MLX_PORT=N            Set port (default: 8080)
# MLX_MAX_TOKENS=N      Set max output tokens (default: 16384)
# MLX_THINKING=0        Disable thinking/reasoning mode (Nemotron only, default: on)

expand_model() {
	case "$1" in
	qwen | qwen3 | coder) echo "lmstudio-community/Qwen3-Coder-30B-A3B-Instruct-MLX-8bit" ;;
	qwen-next | coder-next | next) echo "lmstudio-community/Qwen3-Coder-Next-MLX-4bit" ;;
	glm | glm4 | glm-flash) echo "mlx-community/GLM-4.7-Flash-4bit" ;;
	nemotron | nemo) echo "lmstudio-community/NVIDIA-Nemotron-3-Nano-30B-A3B-MLX-5bit" ;;
	*) echo "$1" ;;
	esac
}

MODEL_INPUT="${MLX_MODEL:-glm}"
MODEL=$(expand_model "$MODEL_INPUT")
PORT="${MLX_PORT:-8080}"
MAX_TOKENS="${MLX_MAX_TOKENS:-16384}"

# Model-specific defaults
EXTRA_ARGS=()
case "$MODEL" in
*Qwen3-Coder-Next*)
	# Qwen3-Coder-Next: 80B MoE, 3B active, 256K context
	# Official recommended settings (no thinking mode)
	TEMP="${MLX_TEMP:-1.0}"
	TOP_P="${MLX_TOP_P:-0.95}"
	TOP_K="${MLX_TOP_K:-40}"
	MIN_P="${MLX_MIN_P:-0.0}"
	echo "Starting MLX-LM server (Qwen3-Coder-Next 80B MoE)..."
	;;
*Qwen3-Coder*)
	# Official Qwen3 recommended settings
	TEMP="${MLX_TEMP:-0.7}"
	TOP_P="${MLX_TOP_P:-0.8}"
	TOP_K="${MLX_TOP_K:-20}"
	MIN_P="${MLX_MIN_P:-0.0}"
	echo "Starting MLX-LM server (Qwen3-Coder)..."
	;;
*GLM-4.7*)
	# GLM-4.7-Flash coding settings (from Z.ai SWE-bench config)
	TEMP="${MLX_TEMP:-0.7}"
	TOP_P="${MLX_TOP_P:-1.0}"
	TOP_K="${MLX_TOP_K:-0}"
	MIN_P="${MLX_MIN_P:-0.0}"
	echo "Starting MLX-LM server (GLM-4.7-Flash)..."
	;;
*Nemotron*)
	# Nemotron-3-Nano: 1M context, multi-token prediction built-in
	# Thinking mode: on (default) uses temp=1.0, off uses temp=0.6
	THINKING="${MLX_THINKING:-1}"
	if [[ "$THINKING" == "1" ]]; then
		TEMP="${MLX_TEMP:-1.0}"
		TOP_P="${MLX_TOP_P:-1.0}"
		EXTRA_ARGS=(--chat-template-args '{"enable_thinking":true}')
		echo "Starting MLX-LM server (Nemotron-3-Nano, thinking ON)..."
	else
		TEMP="${MLX_TEMP:-0.6}"
		TOP_P="${MLX_TOP_P:-0.95}"
		EXTRA_ARGS=(--chat-template-args '{"enable_thinking":false}')
		echo "Starting MLX-LM server (Nemotron-3-Nano, thinking OFF)..."
	fi
	TOP_K="${MLX_TOP_K:-0}"
	MIN_P="${MLX_MIN_P:-0.0}"
	;;
*)
	TEMP="${MLX_TEMP:-0.7}"
	TOP_P="${MLX_TOP_P:-0.9}"
	TOP_K="${MLX_TOP_K:-0}"
	MIN_P="${MLX_MIN_P:-0.0}"
	echo "Starting MLX-LM server..."
	;;
esac

echo "  Model: $MODEL"
echo "  Port: $PORT"
echo "  Max tokens: $MAX_TOKENS"
echo "  Sampling: temp=$TEMP, top-p=$TOP_P, top-k=$TOP_K"
if [[ "$MODEL" == *"Nemotron"* ]]; then
	echo "  Thinking: ${THINKING:-1} (MLX_THINKING=0 to disable)"
fi

echo ""

# Update this path to your mlx_lm.server location
exec mlx_lm.server \
	--model "$MODEL" \
	--port "$PORT" \
	--max-tokens "$MAX_TOKENS" \
	--temp "$TEMP" \
	--top-p "$TOP_P" \
	--top-k "$TOP_K" \
	--min-p "$MIN_P" \
	${EXTRA_ARGS[@]+"${EXTRA_ARGS[@]}"}
